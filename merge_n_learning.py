#2025-08-04 ~ 2025-08-06 ë°ì´í„° ë³‘í•© ë° ì „ì²˜ë¦¬, ëª¨ë¸ í•™ìŠµ + ì‹œê°í™” ì½”ë“œ
import pandas as pd
import numpy as np
import os
import glob
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from matplotlib.ticker import FuncFormatter
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.ensemble import ExtraTreesRegressor, VotingRegressor
from lightgbm import LGBMRegressor
from sklearn.ensemble import RandomForestRegressor

#--------------------------------------------------------------------------------------------------------
# í•œê¸€ í°íŠ¸ ì„¤ì •
font_path = "C:/Windows/Fonts/malgun.ttf"
font_prop = fm.FontProperties(fname=font_path)
plt.rc('font', family=font_prop.get_name())
plt.rcParams['axes.unicode_minus'] = False

# ì‹œêµ°ëª… ì¶”ì¶œ í•¨ìˆ˜
def extract_city_name(filename: str) -> str:
    name = os.path.basename(filename).replace('.csv', '')
    parts = name.split('_')
    if parts[-1][-1] == 'ì‹œ':      # í˜•ì‹: ..._YYYYMM_í™”ì„±ì‹œ
        return parts[-1]
    elif parts[-2][-1] == 'ì‹œ':    # í˜•ì‹: ..._ìˆ˜ì›ì‹œ_YYYYMM
        return parts[-2]
    else:
        raise ValueError(f"ì‹œêµ°ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {filename}")

# CSV ì½ê¸° í•¨ìˆ˜ (UTF-8 â†’ cp949 fallback)
def read_csv_flexible(file_path: str) -> pd.DataFrame:
    try:
        return pd.read_csv(file_path, encoding='utf-8')
    except UnicodeDecodeError:
        return pd.read_csv(file_path, encoding='cp949')

# ë°ì´í„° í´ë” ì§€ì •
data_folder = r'your_card_consumption_data_folder'  # ì‹¤ì œ ë°ì´í„° í´ë” ê²½ë¡œë¡œ ë³€ê²½
files = glob.glob(os.path.join(data_folder, "*.csv"))

# ì „ì²´ ë°ì´í„° ìˆ˜ì§‘
all_data = []

for file in files:
    if not os.path.basename(file).startswith("~$"):
        try:
            city = extract_city_name(file)
            df = read_csv_flexible(file)

            # ë‚ ì§œ ì²˜ë¦¬
            if 'ta_ymd' not in df.columns:
                print(f"[ëˆ„ë½] 'ta_ymd' ì—†ìŒ: {file}")
                continue

            df['ta_ymd'] = pd.to_datetime(df['ta_ymd'], format='%Y%m%d', errors='coerce')
            df['region'] = city

            # ì»¤í”¼/ìŒë£Œ í•„í„°ë§
            df = df[df['card_tpbuz_nm_2'] == 'ì»¤í”¼/ìŒë£Œ']

            all_data.append(df)
            print(f"[ë¡œë“œ ì™„ë£Œ] {file} - {len(df)} rows")
        except Exception as e:
            print(f"[ì˜¤ë¥˜] {file}: {e}")

# í•˜ë‚˜ë¡œ ë³‘í•©
card_df = pd.concat(all_data, ignore_index=True)

card_df['ym'] = card_df['ta_ymd'].dt.to_period('M').astype(str)


# ì§€ì—­ + ì—°ì›” ë‹¨ìœ„ ì§‘ê³„ (ì´ ê¸ˆì•¡ ë° ê±´ìˆ˜)
card_agg = card_df.groupby(['region', 'ym']).agg({
    'amt': 'sum',
    'cnt': 'sum'
}).reset_index().rename(columns={'amt': 'total_amt', 'cnt': 'total_cnt'})

card_agg['avg_amt_per_cnt'] = card_agg['total_amt'] / card_agg['total_cnt']

# ----------------------------------------------------------------------------------

# 2. ì˜ì—…/íì—… ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
store_df = pd.read_csv(r'your_cafe_data_file', encoding='cp949')
store_df['ì¸í—ˆê°€ì¼ì'] = pd.to_datetime(store_df['ì¸í—ˆê°€ì¼ì'], errors='coerce')
store_df['íì—…ì¼ì'] = pd.to_datetime(store_df['íì—…ì¼ì'], errors='coerce')
store_df['region'] = store_df['ì†Œì¬ì§€ì „ì²´ì£¼ì†Œ'].str.extract(r'ê²½ê¸°ë„\s(\S+?)[\s,]')

# ì¸í—ˆê°€/íì—… ì›” ë‹¨ìœ„ ì¶”ì¶œ
store_df['open_ym'] = store_df['ì¸í—ˆê°€ì¼ì'].dt.to_period('M').astype(str)
store_df['close_ym'] = store_df['íì—…ì¼ì'].dt.to_period('M').astype(str)

# ì§€ì—­ + ì—°ì›” ë‹¨ìœ„ë¡œ ê°œìˆ˜ ì§‘ê³„
open_count = store_df.groupby(['region', 'open_ym']).size().reset_index(name='n_open')
close_count = store_df.groupby(['region', 'close_ym']).size().reset_index(name='n_close')

# ----------------------------------------------------------------------------------

# 3. ë¸Œëœë“œ í‰íŒ ì§€ìˆ˜ ì „ì²˜ë¦¬
brand_df = pd.read_csv(r'your_brand_reputation_file', encoding='cp949')

# ì—´ ì´ë¦„ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
value_cols = [col for col in brand_df.columns if 'ë¸Œëœë“œí‰íŒì§€ìˆ˜' in col]
brand_long = pd.melt(brand_df, id_vars=['ìˆœìœ„'], value_vars=value_cols,
                     var_name='ym', value_name='brand_index')

# '2020ë…„8ì›”_ë¸Œëœë“œí‰íŒì§€ìˆ˜' â†’ '2020-08'
brand_long['brand'] = pd.melt(brand_df, id_vars=['ìˆœìœ„'], value_vars=[col.replace('ë¸Œëœë“œí‰íŒì§€ìˆ˜', 'ì»¤í”¼') for col in value_cols])['value']
brand_long['ym'] = brand_long['ym'].str.extract(r'(\d{4})ë…„(\d{1,2})ì›”').apply(lambda x: f"{x[0]}-{int(x[1]):02}", axis=1)

# ì›”ë³„ Top1 ë¸Œëœë“œ ì ìˆ˜ë§Œ ì‚¬ìš© (ë˜ëŠ” í‰ê· ì ìˆ˜ ë“±ë„ ê°€ëŠ¥)
brand_top1 = brand_long[brand_long['ìˆœìœ„'] == 1][['ym', 'brand_index']].rename(columns={'brand_index': 'top1_brand_index'})

# ----------------------------------------------------------------------------------

# 4. í†µí•©
# ìš°ì„  ì§€ì—­ + ymì„ ê¸°ì¤€ìœ¼ë¡œ ì¹´ë“œ + ê°œì—… + íì—…
df_merge = card_agg.copy()
df_merge = df_merge.merge(open_count.rename(columns={'open_ym': 'ym'}), on=['region', 'ym'], how='left')
df_merge = df_merge.merge(close_count.rename(columns={'close_ym': 'ym'}), on=['region', 'ym'], how='left')

# ê²°ì¸¡ê°’ 0ìœ¼ë¡œ ì²˜ë¦¬
df_merge[['n_open', 'n_close']] = df_merge[['n_open', 'n_close']].fillna(0)

# ë¸Œëœë“œ í‰íŒ ì§€ìˆ˜ëŠ” ì „ì²´ ì§€ì—­ì— ê³µí†µ ì ìš©
df_merge = df_merge.merge(brand_top1, on='ym', how='left')

save_path = r'C:\develop\AI_camp\project2\merged_data.csv'
df_merge.to_csv(save_path, index=False, encoding='utf-8-sig')
print(f"[ì €ì¥ ì™„ë£Œ] {save_path}")


#----------------------------------------------------------------



# ë°ì´í„° ì¤€ë¹„
df = df_merge.copy()

# ë‚ ì§œ ë³€í™˜
df['ym'] = pd.to_datetime(df['ym'], errors='coerce')
df['ym_num'] = df['ym'].dt.year * 100 + df['ym'].dt.month
df['month'] = df['ym'].dt.month

# ê³„ì ˆ íŒŒìƒ ë³€ìˆ˜ (ë´„:1, ì—¬ë¦„:2, ê°€ì„:3, ê²¨ìš¸:4)
def get_season(month):
    if month in [3, 4, 5]:
        return 1  # ë´„
    elif month in [6, 7, 8]:
        return 2  # ì—¬ë¦„
    elif month in [9, 10, 11]:
        return 3  # ê°€ì„
    else:
        return 4  # ê²¨ìš¸

df['season'] = df['month'].apply(get_season)

# íì—…ë¥  ì¶”ê°€
df['íì—…ë¥ '] = df['n_close'] / (df['n_open'] + df['n_close'])

# ê°œíì—… ë¹„ìœ¨
df['open_close_ratio'] = df['n_close'] / (df['n_open'] + 1)

# ì§€ì—­ ê¸°ì¤€ ì •ë ¬ (ì¦ê°ë¥  íŒŒìƒì„ ìœ„í•´)
df.sort_values(['region', 'ym'], inplace=True)

# ì¦ê°ë¥  íŒŒìƒ ë³€ìˆ˜
df['open_rate_change'] = df.groupby('region')['n_open'].pct_change()
df['close_rate_change'] = df.groupby('region')['n_close'].pct_change()


df['brand_index_change'] = df['top1_brand_index'].pct_change()


# ----------------------------------------------------------------------------------


# 1. ì›ë‘ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
bean_df = pd.read_csv(r'C:\develop\AI_camp\project2\ì›ë‘ê°€ê²©ë¹„êµë°ì´í„°.csv')

# ì»¬ëŸ¼ëª… ì •ë¦¬ (í•„ìš”ì‹œ)
bean_df.rename(columns={
    'ì—°ë„': 'year',
    'ì•„ë¼ë¹„ì¹´_í•œì”ë‹¹(ì›)': 'arabica_price',
    'ë¡œë¶€ìŠ¤íƒ€_í•œì”ë‹¹(ì›)': 'robusta_price'
}, inplace=True)

# 7:3 ê°€ì¤‘ í‰ê·  ì›ë‘ ê°€ê²© ê³„ì‚°
bean_df['weighted_price'] = bean_df['arabica_price'] * 0.7 + bean_df['robusta_price'] * 0.3

# ì „ë…„ ëŒ€ë¹„ ë³€í™”ìœ¨ (ì¶”ê°€ í”¼ì²˜ìš©)
bean_df['weighted_price_change'] = bean_df['weighted_price'].pct_change()

# ë©”ì¸ dfì—ì„œ ì—°ë„ ì¶”ì¶œ
df['year'] = df['ym'].dt.year

# ë³‘í•©
df = df.merge(bean_df[['year', 'weighted_price', 'weighted_price_change']], on='year', how='left')

#-----------------------------------------------------------------------------------

# ìµœì €ì„ê¸ˆ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
wage_df = pd.read_csv(r'C:\develop\AI_camp\project2\ìµœì €ì„ê¸ˆ_2016_2025.csv')  # íŒŒì¼ ê²½ë¡œ ë§ê²Œ ìˆ˜ì •

# ì»¬ëŸ¼ëª… ì •ë¦¬
wage_df.rename(columns={
    'ì—°ë„': 'year',
    'í‰ê· ìµœì €ì„ê¸ˆ': 'min_wage',
    'ì „ë…„ëŒ€ë¹„ì¸ìƒë¥ (%)': 'wage_increase'
}, inplace=True)

# ë³‘í•©
df = df.merge(wage_df, on='year', how='left')

#--------------------------------------------------------------------------------
# ì†Œê·œëª¨ ì„ëŒ€ë£Œ ë¶ˆëŸ¬ì˜¤ê¸° ë° ë³‘í•© ì²˜ë¦¬
# ì†Œê·œëª¨ ì„ëŒ€ë£Œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ê³„ì ˆ ê¸°ì¤€ í™•ì¥

# 1. ë¶ˆëŸ¬ì˜¤ê¸°
rent_small_df = pd.read_csv(r'your_small_rent_file', encoding='cp949')
rent_big_df = pd.read_csv(r'your_big_rent_file', encoding='cp949')

# 2. 'ì§€ì—­(ì¶”ì¶œ)' ì—´ ê¸°ë°˜ìœ¼ë¡œ region ì •ë¦¬ + 'ì‹œ' ë¶™ì´ê¸°
rent_small_df['region'] = rent_small_df['ì§€ì—­(ì¶”ì¶œ)'].astype(str).str.strip() + 'ì‹œ'
rent_big_df['region'] = rent_big_df['ì§€ì—­(ì¶”ì¶œ)'].astype(str).str.strip() + 'ì‹œ'

# ê³µë°± ì œê±° (ì—´ ì´ë¦„ ì•ë’¤ ê³µë°± ì œê±°)
rent_big_df.columns = rent_big_df.columns.str.strip()
rent_small_df.columns = rent_small_df.columns.str.strip()

# rent_small ì²˜ë¦¬
value_cols_small = [col for col in rent_small_df.columns if 'ë…„' in col]
rent_small_long = rent_small_df.melt(
    id_vars=['region'],
    value_vars=value_cols_small,
    var_name='year',
    value_name='rent_small'
)

# rent_big ì²˜ë¦¬
value_cols_big = [col for col in rent_big_df.columns if 'ë…„' in col]
rent_big_long = rent_big_df.melt(
    id_vars=['region'],
    value_vars=value_cols_big,
    var_name='year',
    value_name='rent_big'
)


# 4. ì—°ë„ ì¶”ì¶œ ë° ì •ìˆ˜í˜• ë³€í™˜
rent_small_long['year'] = rent_small_long['year'].str.extract(r'(\d{4})')
rent_small_long = rent_small_long.dropna(subset=['year'])
rent_small_long['year'] = rent_small_long['year'].astype(int)

rent_big_long['year'] = rent_big_long['year'].str.extract(r'(\d{4})')
rent_big_long = rent_big_long.dropna(subset=['year'])
rent_big_long['year'] = rent_big_long['year'].astype(int)


# 5. ê³„ì ˆ í™•ì¥
season_list = [1, 2, 3, 4]
expanded_rows = []
for _, row in rent_small_long.iterrows():
    for season in season_list:
        expanded_rows.append({
            'region': row['region'],
            'year': row['year'],
            'season': season,
            'rent_small': row['rent_small']
        })
rent_small_season = pd.DataFrame(expanded_rows)

# ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ëŒ€í˜• ì„ëŒ€ë£Œë„ ê³„ì ˆ í™•ì¥
expanded_rows_big = []
for _, row in rent_big_long.iterrows():
    for season in season_list:
        expanded_rows_big.append({
            'region': row['region'],
            'year': row['year'],
            'season': season,
            'rent_big': row['rent_big']
        })
rent_big_season = pd.DataFrame(expanded_rows_big)

# 6. ë©”ì¸ df ë³‘í•©
df = df.merge(rent_small_season, on=['region', 'year', 'season'], how='left')
df = df.merge(rent_big_season, on=['region', 'year', 'season'], how='left')

# ------------------------------------------------------------------------------------
# NaN í‰ê· ìœ¼ë¡œ ëŒ€ì²´ (ìƒê´€ê´€ê³„ ë¶„ì„ ë° ê³ ì •ë¹„ ê³„ì‚°ì„ ìœ„í•´)
mean_rent_small = df['rent_small'].mean()
df['rent_small'] = df['rent_small'].fillna(mean_rent_small)

mean_rent_big = df['rent_big'].mean()
df['rent_big'] = df['rent_big'].fillna(mean_rent_big)

# ì„ëŒ€ë£Œ ê³„ì‚° (ë©´ì  ê°€ì • ì ìš©)
avg_area = 30  # í•„ìš”ì‹œ ìˆ˜ì •

df['rent_cost_small'] = df['rent_small'] * avg_area
df['rent_cost_big'] = df['rent_big'] * avg_area




# ì›í•˜ëŠ” ë°©ì‹ì— ë”°ë¼ ì„ íƒ or í‰ê· 
df['avg_rent_cost'] = df[['rent_cost_small', 'rent_cost_big']].mean(axis=1)

# ê³ ì •ë¹„ ê³„ì‚°
df['fixed_cost'] = df['min_wage'] + df['weighted_price'] + df['avg_rent_cost']
#----------------------------------------------------------------------------------------


# ìƒê´€ë¶„ì„ ëŒ€ìƒ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì„ íƒ
corr_cols = [
    'íì—…ë¥ ',
    'top1_brand_index', 'season', 'weighted_price', 'min_wage',
    'fixed_cost', 'avg_amt_per_cnt', 'avg_rent_cost', 'brand_index_change', 'weighted_price_change', 'wage_increase'
]

df_corr = df[corr_cols].copy()
df_corr = df_corr.fillna(df_corr.mean())

# ìƒê´€ê³„ìˆ˜ ê³„ì‚°
target_corr = df_corr.corr()['íì—…ë¥ '].drop('íì—…ë¥ ').sort_values()

# í•œêµ­ì–´ ë³€ìˆ˜ëª… ë§¤í•‘
label_map = {
    'total_amt': 'ì¹´ë“œ ì†Œë¹„ ê¸ˆì•¡',
    'total_cnt': 'ì¹´ë“œ ì†Œë¹„ ê±´ìˆ˜',
    'n_open': 'ì‹ ê·œ ê°œì—… ìˆ˜',
    'n_close': 'íì—… ìˆ˜',
    'open_close_ratio': 'ê°œíì—… ë¹„ìœ¨',
    'open_rate_change': 'ê°œì—… ì¦ê°ë¥ ',
    'close_rate_change': 'íì—… ì¦ê°ë¥ ',
    'top1_brand_index': 'ë¸Œëœë“œ í‰íŒì§€ìˆ˜',
    'ym_num': 'ì—°ì›”',
    'season': 'ê³„ì ˆ',
    'brand_index_change': 'ë¸Œëœë“œ ì§€ìˆ˜ ë³€í™”ìœ¨',
    'weighted_price': 'í‰ê·  ì›ë‘ ê°€ê²©',
    'weighted_price_change': 'ì›ë‘ ê°€ê²© ë³€í™”ìœ¨',
    'min_wage': 'ìµœì €ì„ê¸ˆ',
    'wage_increase': 'ìµœì €ì„ê¸ˆ ì¸ìƒë¥ ',
    'fixed_cost': 'ê³ ì •ë¹„',
    'rent_cost_small': 'ì†Œê·œëª¨ ì„ëŒ€ë£Œ',
    'avg_amt_per_cnt': 'ê±´ë‹¹ í‰ê·  ì†Œë¹„ ê¸ˆì•¡',
    'rent_cost_big': 'ëŒ€ê·œëª¨ ì„ëŒ€ë£Œ',
    'avg_rent_cost': 'í‰ê·  ì„ëŒ€ë£Œ'
}
target_corr.index = target_corr.index.map(label_map)

# ì‹œê°í™”
plt.figure(figsize=(8, 5))
ax = sns.barplot(x=target_corr.values, y=target_corr.index, palette='coolwarm')

# ìˆ˜ì¹˜ í‘œì‹œ
for i, (value, label) in enumerate(zip(target_corr.values, target_corr.index)):
    plt.text(value + 0.01 * (1 if value >= 0 else -1), i, f'{value:.2f}',
             va='center', ha='left' if value >= 0 else 'right', fontsize=7)

plt.title("íì—…ë¥ ê³¼ ë³€ìˆ˜ë³„ ìƒê´€ê³„ìˆ˜", fontsize=14)
plt.xlabel("ìƒê´€ê³„ìˆ˜ (Correlation with íì—…ë¥ )")
plt.ylabel("")
plt.grid(axis='x', linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

#-------------------------------------------------------------------------------------------
# 8. íˆíŠ¸ë§µ ì‹œê°í™”
corr_matrix = df_corr.corr()
corr_matrix.rename(columns=label_map, index=label_map, inplace=True)

plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', linewidths=0.5)
plt.title("ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ", fontsize=16)
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()


#---------------------------------------------------------------------------------------------


# 3. ë¶„ì„ìš© í”¼ì²˜/íƒ€ê²Ÿ ë¶„ë¦¬
target_col = 'íì—…ë¥ '
non_feature_cols = [
    'total_amt', 'total_cnt', 'íì—…ë¥ ', 'open_rate_change', 'close_rate_change', 'brand_index_change', 'rent_big', 'rent_small',
    'weighted_price_change', 'wage_increase', 'rent_cost_small', 'rent_cost_big', 'year', 'ym', 'region', 'ym_num', 'month', 'n_close', 'n_open'
]



# ìœ ì¼ê°’ì´ ì „ë¶€ ë‹¤ë¥¸ ì‹ë³„ì ì œê±°
for col in df.columns:
    if df[col].dtype == object and df[col].nunique() == df.shape[0]:
        non_feature_cols.append(col)

X = df.drop(non_feature_cols, axis=1)
y = df[target_col]

# 4. ë²”ì£¼í˜• ë³€ìˆ˜ ìˆ˜ì¹˜ ì¸ì½”ë”©
for c in X.select_dtypes(include='object').columns:
    X[c] = X[c].astype('category').cat.codes

# 5. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
#---------------------------------------------------------------------------------------------

def print_metrics(y_true, y_pred, model_name="ëª¨ë¸ëª…"):
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)

    print(f"\n {model_name} ì„±ëŠ¥ í‰ê°€")
    print(f"  - MAE : {mean_absolute_error(y_true, y_pred):.4f}")
    print(f"  - RMSE: {rmse:.4f}")
    print(f"  - RÂ²  : {r2_score(y_true, y_pred):.4f}")



lgbm = LGBMRegressor(
    n_estimators=500,          # ì´ íŠ¸ë¦¬ ê°œìˆ˜ (ë§ì„ìˆ˜ë¡ ì•ˆì •ì ì´ì§€ë§Œ ëŠë¦¼)
    learning_rate=0.03,        # í•™ìŠµë¥  (ë‚®ì„ìˆ˜ë¡ ì²œì²œíˆ í•™ìŠµ â†’ ê³¼ì í•© ë°©ì§€)
    max_depth=4,               # ê°œë³„ íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´ (ì‘ê²Œ ì œí•œ â†’ ë³µì¡ë„ ê°ì†Œ)
    min_child_samples=30,      # ë¦¬í”„ ë…¸ë“œê°€ ê°€ì ¸ì•¼ í•  ìµœì†Œ ìƒ˜í”Œ ìˆ˜ (ì‘ì„ìˆ˜ë¡ ê³¼ì í•© ìœ„í—˜ ì¦ê°€)
    subsample=0.7,             # ê° íŠ¸ë¦¬ í•™ìŠµ ì‹œ ì‚¬ìš©í•  ìƒ˜í”Œ ë¹„ìœ¨ (ìƒ˜í”Œë§ â†’ ì¼ë°˜í™” í–¥ìƒ)
    colsample_bytree=0.7,      # ê° íŠ¸ë¦¬ í•™ìŠµ ì‹œ ì‚¬ìš©í•  í”¼ì²˜ ë¹„ìœ¨ (í”¼ì²˜ ìƒ˜í”Œë§ â†’ ê³¼ì í•© ë°©ì§€)
    reg_alpha=0.5,             # L1 ì •ê·œí™” (í”¼ì²˜ ì„ íƒ ì„±ê²©, ê³¼ì í•© ë°©ì§€)
    reg_lambda=0.5,            # L2 ì •ê·œí™” (ê°€ì¤‘ì¹˜ í¬ê¸°ë¥¼ ì œí•œí•˜ì—¬ ì¼ë°˜í™” í–¥ìƒ)
    random_state=42,           # ê²°ê³¼ ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ
    n_jobs=-1                  # ê°€ëŠ¥í•œ ëª¨ë“  ì½”ì–´ ì‚¬ìš©
)


et = ExtraTreesRegressor(
    n_estimators=300,          # íŠ¸ë¦¬ ê°œìˆ˜
    max_depth=7,               # íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´ ì œí•œ
    min_samples_leaf=5,        # ë¦¬í”„ ë…¸ë“œì˜ ìµœì†Œ ìƒ˜í”Œ ìˆ˜ (ë„ˆë¬´ ì‘ìœ¼ë©´ ê³¼ì í•© ìœ„í—˜)
    max_features='sqrt',       # ê° ë…¸ë“œ ë¶„í•  ì‹œ ì‚¬ìš©í•  í”¼ì²˜ ê°œìˆ˜ (ì „ì²´ í”¼ì²˜ì˜ âˆšê°œ)
    random_state=42            # ì‹œë“œ ê³ ì •
)


rf = RandomForestRegressor(
    n_estimators=300,          # íŠ¸ë¦¬ ê°œìˆ˜
    max_depth=7,               # íŠ¸ë¦¬ ê¹Šì´ ì œí•œ
    min_samples_leaf=5,        # ë¦¬í”„ ë…¸ë“œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
    max_features='sqrt',       # í”¼ì²˜ ìƒ˜í”Œë§ ë°©ì‹ (ì „ì²´ í”¼ì²˜ ì¤‘ âˆšê°œ)
    random_state=42            # ì‹œë“œ ê³ ì •
)
voting = VotingRegressor(estimators=[
    ('lgbm', lgbm),
    ('et', et),
    ('rf', rf)
])

lgbm.fit(X_train, y_train)
y_pred_lgbm = lgbm.predict(X_test)
print_metrics(y_test, y_pred_lgbm, model_name="LightGBM")

# ğŸ”¹ ExtraTrees ë‹¨ë… í•™ìŠµ
et.fit(X_train, y_train)
y_pred_et = et.predict(X_test)
print_metrics(y_test, y_pred_et, model_name="ExtraTrees")

# ğŸ”¹ RandomForest ë‹¨ë… í•™ìŠµ
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)
print_metrics(y_test, y_pred_rf, model_name="RandomForest")

voting.fit(X_train, y_train)
y_pred_voting = voting.predict(X_test)

print_metrics(y_test, y_pred_voting, model_name="Voting ì•™ìƒë¸” - L1, L2 ê·œì œ ì¶”ê°€(ê³¼ì í•© ë°©ì§€)")

# ExtraTreesRegressor ëª¨ë¸ ë³„ë„ í•™ìŠµ (ë³€ìˆ˜ ì¤‘ìš”ë„ ì¶”ì¶œìš©)
et.fit(X_train, y_train)

# ë³€ìˆ˜ ì¤‘ìš”ë„ ì¶”ì¶œ ë° ì •ë ¬
importances = et.feature_importances_
indices = np.argsort(importances)[::-1]
features = X.columns

# í•œê¸€ ë¼ë²¨ ì ìš©
feature_labels = [label_map.get(f, f) for f in features[indices]]

# ì‹œê°í™”
plt.figure(figsize=(10, 6))
sns.barplot(x=importances[indices], y=feature_labels, palette='coolwarm')
plt.title("ë³€ìˆ˜ ì¤‘ìš”ë„ (ExtraTrees ê¸°ì¤€)")
plt.xlabel("ì¤‘ìš”ë„")
plt.ylabel("ë³€ìˆ˜ëª…")
plt.tight_layout()
plt.show()


#---------------------------------------------------------------------------------------------
